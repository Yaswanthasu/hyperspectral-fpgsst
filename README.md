# ğŸ›°ï¸ Frequency-Prompt Guided Spectralâ€“Spatial Transformer (FPGSST)
**_A Deep Transformer-based Approach for Hyperspectral Image Classification_**

---

## ğŸŒ Overview

This repository contains the implementation of the paper-inspired model **FPGSST (Frequency-Prompt Guided Spectralâ€“Spatial Transformer)** for **Hyperspectral Image Classification (HSI)**.  
The model integrates **frequency-domain prompting**, **spectral-spatial attention**, and **transformer-based fusion** to achieve superior accuracy on benchmark HSI datasets.

The project supports training, evaluation, and visualization across multiple datasets:
- **Pavia University (PaviaU)**
- **HyRANK (Loukia)**
- **WHU-Hi LongKou**

---

## ğŸ§  Key Features
âœ… Transformer-based architecture for spectralâ€“spatial learning  
âœ… Frequency-domain prompting for enhanced spectral discrimination  
âœ… Modular design â€” supports multiple datasets and models  
âœ… End-to-end training and evaluation pipeline  
âœ… TensorBoard support for tracking training progress  
âœ… Visualization tools for classification maps and performance comparison  

---

## ğŸ“‚ Project Structure
hyperspectral-project/
â”œâ”€â”€ datasets/ # Preprocessed HSI datasets (.mat, .npz)
â”œâ”€â”€ models/ # Model architectures (FPGSST, HybridSN, etc.)
â”œâ”€â”€ modules/ # Core modules (Attention, Augmentation)
â”œâ”€â”€ preprocess/ # Data preprocessing scripts
â”œâ”€â”€ experiments/ # Trained models and logs
â”œâ”€â”€ results/ # Confusion matrices, performance plots, prediction maps
â”œâ”€â”€ train.py # Main training script
â”œâ”€â”€ evaluate.py # Evaluation and metrics
â”œâ”€â”€ save_pred_map_full.py # Generate full HSI prediction maps
â”œâ”€â”€ visualize_results.py # Generate final classification map figures
â””â”€â”€ plot_results.py # Compare OA, AA, and Kappa across datasets
--

## ğŸ§¾ Requirements
Install all dependencies in your conda environment:
```bash
conda create -n hyper python=3.9
conda activate hyper
pip install torch torchvision torchaudio matplotlib numpy scipy scikit-learn tqdm tensorboard
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
CUDA_VISIBLE_DEVICES=0 python train.py --dataset PaviaU --model FPGSST --bs 64 --epochs 30 --out experiments
python run_all_datasets.py
#Evaluate trained models and generate metrics:
python evaluate.py --npz datasets/PaviaU/PaviaU_preprocessed.npz \
                   --ckpt experiments/PaviaU/FPGSST/FPGSST_best.pth \
                   --model FPGSST
#Generate full-resolution classification maps:
python save_pred_map_full.py --dataset PaviaU \
  --ckpt experiments/PaviaU/FPGSST/FPGSST_best.pth \
  --patch 9 --batch 1024 --device cuda --out results
#Generate visual comparison of results:
python visualize_results.py
python plot_results.py
```
Outputs:

results/dataset_comparison.png

results/individual_results/ (per-dataset accuracy plots)

results/confusion_matrix_*.png

ğŸ“Š Example Results
| Dataset         | OA (%) | AA (%) | Kappa  |
| --------------- | ------ | ------ | ------ |
| PaviaU          | 94.26  | 95.44  | 0.9251 |
| Loukia (HyRANK) | 41.20  | 20.03  | 0.2145 |
| WHU-Hi LongKou  | 33.94  | 22.13  | 0.2523 |

ğŸ§© Model Architecture
<p align="center"> <img src="https://github.com/Yaswanthasu/hyperspectral-fpgsst/assets/transformer-architecture-diagram.png" width="700"> </p>

FPGSST Architecture:

Spectralâ€“Spatial Transformer backbone

Frequency Prompt Module (FPM) â€” extracts DCT-based spectral prompts

Dual-branch attention (Spectral & Spatial)

Fusion Transformer for joint feature learning

ğŸ§  Citation
If you use this work, please cite:
@misc{yaswanthasu2025fpgsst,
  title={Frequency-Prompt Guided Spectralâ€“Spatial Transformer for Hyperspectral Image Classification},
  author={Yaswanthasu, A.Y.V. Trinadh},
  year={2025},
  publisher={GitHub},
  journal={https://github.com/Yaswanthasu/hyperspectral-fpgsst}
}
Hereâ€™s the architecture diagram for the Frequency-Prompt Guided Spectralâ€“Spatial Transformer (FPGSST):
<p align="center">
  <img src="assets/fpgsst_architecture.png" width="700">
</p>

